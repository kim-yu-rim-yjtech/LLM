{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "마을 골목길에 퇴비를 두어 악취 발생이 심하니 이동조치 해주세요.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, AutoConfig\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"fiveflow/roberta-base-spacing\")\n",
    "roberta = AutoModelForTokenClassification.from_pretrained(\"fiveflow/roberta-base-spacing\")\n",
    "\n",
    "# 새로운 문장 예시\n",
    "org_text = \"마을골목길에퇴비를두어 악 취 발생이 심 하니 이동 조치해 주세요.\".replace(\" \", \"\")  # 공백 제거\n",
    "label = [\"UNK\", \"PAD\", \"O\", \"B\", \"I\", \"E\", \"S\"] \n",
    "\"\"\"\n",
    "UNK: 알 수 없는 토큰에 대한 태그\n",
    "PAD: 패딩에 해당하는 태그(문장의 길이를 맞추기 위해 사용)\n",
    "O: 띄어쓰기가 필요하지 않은 문자\n",
    "B: 새로운 단어의 시작 부분\n",
    "I: 단어의 중간 부분\n",
    "E: 단어의 끝 부분 - 해당 태그가 있으면 띄어쓰기가 필요함\n",
    "S: 단일 문자로 구성된 단어\n",
    "\"\"\"\n",
    "\n",
    "# char 단위로 토큰화\n",
    "token_list = [tokenizer.cls_token_id]\n",
    "for char in org_text:\n",
    "    token_list.append(tokenizer.encode(char)[1]) \n",
    "token_list.append(tokenizer.eos_token_id)\n",
    "tkd = torch.tensor(token_list).unsqueeze(0)\n",
    "\n",
    "output = roberta(tkd).logits\n",
    "\n",
    "_, pred_idx = torch.max(output, dim=2)\n",
    "tags = [label[idx] for idx in pred_idx.squeeze()][1:-1]\n",
    "pred_sent = \"\"\n",
    "for char_idx, spc_idx in enumerate(pred_idx.squeeze()[1:-1]):\n",
    "    # \"E\" 태그를 기준으로 띄어쓰기\n",
    "    if label[spc_idx] == \"E\": \n",
    "        pred_sent += org_text[char_idx] + \" \"\n",
    "    else: \n",
    "        pred_sent += org_text[char_idx]\n",
    "\n",
    "print(pred_sent.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변환 후 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yjtech2/Desktop/yurim/anaconda3/envs/venv-llm/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-13 16:43:28.800008: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-13 16:43:28.826413: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-13 16:43:29.167869: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"fiveflow/roberta-base-spacing\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"fiveflow/roberta-base-spacing\")\n",
    "\n",
    "# GPU 사용 가능시 GPU 사용\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# 레이블 정의\n",
    "label = [\"UNK\", \"PAD\", \"O\", \"B\", \"I\", \"E\", \"S\"]\n",
    "\n",
    "def apply_spacing_correction(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    try:\n",
    "        # 최대 토큰 길이 설정\n",
    "        max_token_length = 512 - 2  # CLS와 SEP 토큰을 위한 자리\n",
    "        \n",
    "        # 공백 제거된 텍스트 준비\n",
    "        org_text = text.replace(\" \", \"\")\n",
    "        corrected_sentences = []\n",
    "        \n",
    "        # 512 토큰 단위로 나누기\n",
    "        for start_idx in range(0, len(org_text), max_token_length):\n",
    "            chunk = org_text[start_idx:start_idx + max_token_length]\n",
    "            token_list = [tokenizer.cls_token_id]\n",
    "            for char in chunk:\n",
    "                token_list.extend(tokenizer.encode(char)[1:-1])  # CLS, SEP 토큰 제외\n",
    "            token_list.append(tokenizer.sep_token_id)\n",
    "            \n",
    "            tkd = torch.tensor(token_list).unsqueeze(0).to(device)\n",
    "            \n",
    "            # 모델 예측\n",
    "            with torch.no_grad():\n",
    "                outputs = model(tkd)\n",
    "                pred_idx = torch.argmax(outputs.logits, dim=-1)\n",
    "            \n",
    "            # 예측 결과를 문자열로 변환\n",
    "            pred_sent = \"\"\n",
    "            for char_idx, spc_idx in enumerate(pred_idx.squeeze()[1:-1]):\n",
    "                if char_idx >= len(chunk):  # 인덱스 범위 체크\n",
    "                    break\n",
    "                \n",
    "                curr_label = label[spc_idx]\n",
    "                if curr_label in [\"E\", \"S\"]:  # E나 S 태그가 있으면 띄어쓰기 추가\n",
    "                    pred_sent += chunk[char_idx] + \" \"\n",
    "                else:\n",
    "                    pred_sent += chunk[char_idx]\n",
    "            \n",
    "            corrected_sentences.append(pred_sent.strip())\n",
    "        \n",
    "        # 모든 청크를 다시 합치기\n",
    "        final_text = \" \".join(corrected_sentences)\n",
    "        return final_text.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "        return text  # 에러 발생시 원본 텍스트 반환\n",
    "\n",
    "def process_dataframe(df, text_column):\n",
    "    # 진행바 표시\n",
    "    tqdm.pandas(desc=\"Processing spacing correction\")\n",
    "    \n",
    "    # 띄어쓰기 교정 적용\n",
    "    df[\"res_sentence\"] = df[text_column].progress_apply(apply_spacing_correction)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing spacing correction: 100%|██████████| 36000/36000 [01:50<00:00, 324.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "with open('/home/yjtech2/Desktop/yurim/LLM/DATA/띄어쓰기문장부호오류.json', 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "    \n",
    "data = []\n",
    "for item in json_data['data']:\n",
    "    if 'annotation' in item:\n",
    "        annotation = item['annotation']\n",
    "        \n",
    "        if 'err_sentence' in annotation and 'cor_sentence' in annotation:\n",
    "            data.append({\n",
    "                'err_sentence': annotation['err_sentence'],\n",
    "                'cor_sentence': annotation['cor_sentence']\n",
    "            })\n",
    "            \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "if __name__ == \"__main__\":        \n",
    "    # 띄어쓰기 교정 처리\n",
    "    processed_df = process_dataframe(df, \"err_sentence\")\n",
    "    print('처리 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비교 완료\n",
      "정확도:  0.7749166666666667\n",
      "비율 평균:  0.916460055555547\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def add_comparison_columns(df):\n",
    "    \n",
    "    def calculate_spacing_similarity(row):\n",
    "        \"\"\"\n",
    "        띄어쓰기를 포함한 두 문장 간의 유사도를 계산하는 함수\n",
    "        \"\"\"\n",
    "        if pd.isna(row['res_sentence']) or pd.isna(row['cor_sentence']):\n",
    "            return 0\n",
    "        \n",
    "        # 문장의 띄어쓰기를 유지한 채로 비교\n",
    "        res = row['res_sentence']\n",
    "        cor = row['cor_sentence']\n",
    "        \n",
    "        # 완전히 같으면 1 반환\n",
    "        if res == cor:\n",
    "            return 1.0\n",
    "        \n",
    "        # 다르면 띄어쓰기를 포함한 유사도 계산\n",
    "        similarity = SequenceMatcher(None, res, cor).ratio()\n",
    "        \n",
    "        # 띄어쓰기 패턴의 정확도를 별도로 계산\n",
    "        res_spaces = [i for i, char in enumerate(res) if char == ' ']\n",
    "        cor_spaces = [i for i, char in enumerate(cor) if char == ' ']\n",
    "        \n",
    "        # 공통된 띄어쓰기 위치 수 계산\n",
    "        common_spaces = len(set(res_spaces) & set(cor_spaces))\n",
    "        total_spaces = len(set(res_spaces) | set(cor_spaces))\n",
    "        \n",
    "        # 띄어쓰기 정확도 (공통 띄어쓰기 / 전체 띄어쓰기)\n",
    "        spacing_accuracy = common_spaces / total_spaces if total_spaces > 0 else 1.0\n",
    "        \n",
    "        # 전체 유사도와 띄어쓰기 정확도를 조합 (가중치는 조정 가능)\n",
    "        final_ratio = (similarity + spacing_accuracy) / 2\n",
    "        \n",
    "        return round(final_ratio, 3)\n",
    "    \n",
    "    # check 컬럼 추가 (완전히 같으면 1, 다르면 0)\n",
    "    df['check'] = (df['res_sentence'] == df['cor_sentence']).astype(int)\n",
    "    \n",
    "    # ratio 컬럼 추가 (띄어쓰기를 고려한 유사도 계산)\n",
    "    df['ratio'] = df.apply(calculate_spacing_similarity, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    processed_df = processed_df[['err_sentence', 'res_sentence', 'cor_sentence']]\n",
    "    \n",
    "    def text_clean(text):\n",
    "        # pattern = '([ㄱ-ㅎㅏ-ㅣ]+)'  # 한글 자음, 모음 제거\n",
    "        # text = re.sub(pattern, '', text)\n",
    "        \n",
    "        pattern = '[^\\w\\s]'         # 특수기호제거\n",
    "        text = re.sub(pattern, '', text)\n",
    "\n",
    "        return text \n",
    "    \n",
    "    processed_df['res_sentence'] = processed_df['res_sentence'].apply(text_clean)\n",
    "    processed_df['cor_sentence'] = processed_df['cor_sentence'].apply(text_clean)\n",
    "    \n",
    "    result_df = add_comparison_columns(processed_df)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(\"비교 완료\")\n",
    "    print('정확도: ', (len(result_df[result_df['check'] == 1]) / len(result_df)))\n",
    "    print('비율 평균: ', sum(result_df['ratio']) / len(result_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>err_sentence</th>\n",
       "      <th>res_sentence</th>\n",
       "      <th>cor_sentence</th>\n",
       "      <th>check</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>일손과시간이부족해 검증을 다못했다는 군색한변명은안통한다</td>\n",
       "      <td>일손과 시간이 부족해 검증을 다 못했다는 군색한 변명은 안 통한다</td>\n",
       "      <td>일손과 시간이 부족해 검증을 다 못했다는 군색한 변명은 안 통한다</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>총리 후보가사퇴할때마다대통령에게 오는타격은 엄청나다</td>\n",
       "      <td>총리 후보가 사퇴할 때마다 대통령에게 오는 타격은 엄청나다</td>\n",
       "      <td>총리 후보가 사퇴할 때마다 대통령에게 오는 타격은 엄청나다</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이정부 들어 처음으로 박 대통령에대한부정적평가가 긍정적평가를 넘어선 것이다</td>\n",
       "      <td>이 정부 들어 처음으로 박 대통령에 대한 부정적 평가가 긍정적 평가를 넘어선 것이다</td>\n",
       "      <td>이 정부 들어 처음으로 박 대통령에 대한 부정적 평가가 긍정적 평가를 넘어선 것이다</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>대통령이지지율에일희일비할필요는 없다.</td>\n",
       "      <td>대통령이 지지율에 일희일비할 필요는 없다</td>\n",
       "      <td>대통령이 지지율에 일희일비할 필요는 없다</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>위대한 업적을 남긴지도자일수록 반대여론을 무릅쓴 경우가많다</td>\n",
       "      <td>위대한 업적을 남긴 지도자일수록 반대 여론을 무릅쓴 경우가 많다</td>\n",
       "      <td>위대한 업적을 남긴 지도자일수록 반대 여론을 무릅쓴 경우가 많다</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35995</th>\n",
       "      <td>서울 벗어나면 놀이터가없는마을도</td>\n",
       "      <td>서울 벗어나면 놀이터가 없는 마을도</td>\n",
       "      <td>서울 벗어나면 놀이터가 없는 마을도</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35996</th>\n",
       "      <td>집 밖으로나가 뛰어놀고싶은 어린이들에게 놀이터는 너무 멀리있거나 즐겁게 놀 만한기구...</td>\n",
       "      <td>집 밖으로 나가 뛰어놀고 싶은 어린이들에게 놀이터는 너무 멀리 있거나 즐겁게 놀 만...</td>\n",
       "      <td>집 밖으로 나가 뛰어놀고 싶은 어린이들에게 놀이터는 너무 멀리 있거나 즐겁게 놀 만...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35997</th>\n",
       "      <td>재미가없으니 어린이들이모이지않고 같이 놀 친구가없어서 더욱 갈일이없어진다</td>\n",
       "      <td>재미가 없으니 어린이들이 모이지 않고 같이 놀 친구가 없어서 더욱 갈 일이 없어진다</td>\n",
       "      <td>재미가 없으니 어린이들이 모이지 않고 같이 놀 친구가 없어서 더욱 갈 일이 없어진다</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35998</th>\n",
       "      <td>어린이들이 뛰어놀수있는 공간마저도 지역에따라 격차를 보이고있는것이다</td>\n",
       "      <td>어린이들이 뛰어놀 수 있는 공간마저도 지역에 따라 격차를 보이고 있는 것이다</td>\n",
       "      <td>어린이들이 뛰어놀 수 있는 공간마저도 지역에 따라 격차를 보이고 있는 것이다</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35999</th>\n",
       "      <td>그러나 막상아이들을 키우는 주민들의생각은 다르다</td>\n",
       "      <td>그러나 막상 아이들을 키우는 주민들의 생각은 다르다</td>\n",
       "      <td>그러나 막상 아이들을 키우는 주민들의 생각은 다르다</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            err_sentence  \\\n",
       "0                         일손과시간이부족해 검증을 다못했다는 군색한변명은안통한다   \n",
       "1                           총리 후보가사퇴할때마다대통령에게 오는타격은 엄청나다   \n",
       "2              이정부 들어 처음으로 박 대통령에대한부정적평가가 긍정적평가를 넘어선 것이다   \n",
       "3                                   대통령이지지율에일희일비할필요는 없다.   \n",
       "4                       위대한 업적을 남긴지도자일수록 반대여론을 무릅쓴 경우가많다   \n",
       "...                                                  ...   \n",
       "35995                                  서울 벗어나면 놀이터가없는마을도   \n",
       "35996  집 밖으로나가 뛰어놀고싶은 어린이들에게 놀이터는 너무 멀리있거나 즐겁게 놀 만한기구...   \n",
       "35997           재미가없으니 어린이들이모이지않고 같이 놀 친구가없어서 더욱 갈일이없어진다   \n",
       "35998              어린이들이 뛰어놀수있는 공간마저도 지역에따라 격차를 보이고있는것이다   \n",
       "35999                         그러나 막상아이들을 키우는 주민들의생각은 다르다   \n",
       "\n",
       "                                            res_sentence  \\\n",
       "0                   일손과 시간이 부족해 검증을 다 못했다는 군색한 변명은 안 통한다   \n",
       "1                       총리 후보가 사퇴할 때마다 대통령에게 오는 타격은 엄청나다   \n",
       "2         이 정부 들어 처음으로 박 대통령에 대한 부정적 평가가 긍정적 평가를 넘어선 것이다   \n",
       "3                                 대통령이 지지율에 일희일비할 필요는 없다   \n",
       "4                    위대한 업적을 남긴 지도자일수록 반대 여론을 무릅쓴 경우가 많다   \n",
       "...                                                  ...   \n",
       "35995                                서울 벗어나면 놀이터가 없는 마을도   \n",
       "35996  집 밖으로 나가 뛰어놀고 싶은 어린이들에게 놀이터는 너무 멀리 있거나 즐겁게 놀 만...   \n",
       "35997     재미가 없으니 어린이들이 모이지 않고 같이 놀 친구가 없어서 더욱 갈 일이 없어진다   \n",
       "35998         어린이들이 뛰어놀 수 있는 공간마저도 지역에 따라 격차를 보이고 있는 것이다   \n",
       "35999                       그러나 막상 아이들을 키우는 주민들의 생각은 다르다   \n",
       "\n",
       "                                            cor_sentence  check  ratio  \n",
       "0                   일손과 시간이 부족해 검증을 다 못했다는 군색한 변명은 안 통한다      1    1.0  \n",
       "1                       총리 후보가 사퇴할 때마다 대통령에게 오는 타격은 엄청나다      1    1.0  \n",
       "2         이 정부 들어 처음으로 박 대통령에 대한 부정적 평가가 긍정적 평가를 넘어선 것이다      1    1.0  \n",
       "3                                 대통령이 지지율에 일희일비할 필요는 없다      1    1.0  \n",
       "4                    위대한 업적을 남긴 지도자일수록 반대 여론을 무릅쓴 경우가 많다      1    1.0  \n",
       "...                                                  ...    ...    ...  \n",
       "35995                                서울 벗어나면 놀이터가 없는 마을도      1    1.0  \n",
       "35996  집 밖으로 나가 뛰어놀고 싶은 어린이들에게 놀이터는 너무 멀리 있거나 즐겁게 놀 만...      1    1.0  \n",
       "35997     재미가 없으니 어린이들이 모이지 않고 같이 놀 친구가 없어서 더욱 갈 일이 없어진다      1    1.0  \n",
       "35998         어린이들이 뛰어놀 수 있는 공간마저도 지역에 따라 격차를 보이고 있는 것이다      1    1.0  \n",
       "35999                       그러나 막상 아이들을 키우는 주민들의 생각은 다르다      1    1.0  \n",
       "\n",
       "[36000 rows x 5 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>err_sentence</th>\n",
       "      <th>res_sentence</th>\n",
       "      <th>cor_sentence</th>\n",
       "      <th>check</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>하지만 국민 지지가 뒷받침되면 국정 운영에 자신감과 탄력이더해진다는점도 분명하다</td>\n",
       "      <td>하지만 국민지지가 뒷받침되면 국정운영에 자신감과 탄력이 더해진다는 점도 분명하다</td>\n",
       "      <td>하지만 국민 지지가 뒷받침되면 국정 운영에 자신감과 탄력이 더해진다는 점도 분명하다</td>\n",
       "      <td>0</td>\n",
       "      <td>0.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>국민 혈세로시장을 틀어막아 달라는것은 어불성설이다.</td>\n",
       "      <td>국민혈세로 시장을 틀어막아 달라는 것은 어불성설이다</td>\n",
       "      <td>국민 혈세로 시장을 틀어막아 달라는 것은 어불성설이다</td>\n",
       "      <td>0</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>차제에문제 병사 관리 실태를 일제히 점검하라</td>\n",
       "      <td>차제에 문제병사 관리 실태를 일제히 점검하라</td>\n",
       "      <td>차제에 문제 병사 관리 실태를 일제히 점검하라</td>\n",
       "      <td>0</td>\n",
       "      <td>0.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>당시에도 군 경계 태세에 구멍이 뚫렸다는 비판이들끓었는데 또 이사단에서 사고가 터졌다.</td>\n",
       "      <td>당시에도 군경계 태세에 구멍이 뚫렸다는 비판이 들끓었는데 또 이 사단에서 사고가 터졌다</td>\n",
       "      <td>당시에도 군 경계 태세에 구멍이 뚫렸다는 비판이 들끓었는데 또 이 사단에서 사고가 터졌다</td>\n",
       "      <td>0</td>\n",
       "      <td>0.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>군 총기사고는 잊을만하면발생한다.</td>\n",
       "      <td>군총기 사고는 잊을 만하면 발생한다</td>\n",
       "      <td>군 총기 사고는 잊을 만하면 발생한다</td>\n",
       "      <td>0</td>\n",
       "      <td>0.487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35964</th>\n",
       "      <td>그러나 딸은죽은 엄마와의추억이 떠올라이미 오래전부터 피아노 레슨을 받지않고있었다.</td>\n",
       "      <td>그러나 딸은 죽은 엄마와의 추억이 떠올라 이미 오래 전부터 피아노 레슨을 받지 않고...</td>\n",
       "      <td>그러나 딸은 죽은 엄마와의 추억이 떠올라 이미 오래전부터 피아노 레슨을 받지 않고 있었다</td>\n",
       "      <td>0</td>\n",
       "      <td>0.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35970</th>\n",
       "      <td>저출산, 저소득층의 사고, 장병의 불확실한 미래는기업의지속가능성을위협하는사회적 문제다.</td>\n",
       "      <td>저출산 저소득층의 사고 장병의 불확실한 미래는 기업의 지속가능성을 위협하는 사회적 문제다</td>\n",
       "      <td>저출산 저소득층의 사고 장병의 불확실한 미래는 기업의 지속 가능성을 위협하는 사회적...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35981</th>\n",
       "      <td>경선에선 역대 최대여성후보 바람</td>\n",
       "      <td>경선에 선 역대 최대 여성 후보 바람</td>\n",
       "      <td>경선에선 역대 최대 여성 후보 바람</td>\n",
       "      <td>0</td>\n",
       "      <td>0.487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35986</th>\n",
       "      <td>최대 관심사는 네이버가 유럽에서 첫선을보일 서비스다</td>\n",
       "      <td>최대 관심사는 네이버가 유럽에서 첫 선을 보일 서비스다</td>\n",
       "      <td>최대 관심사는 네이버가 유럽에서 첫선을 보일 서비스다</td>\n",
       "      <td>0</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35987</th>\n",
       "      <td>라인의 경우 일본에서 첫선을보인 뒤 유럽에서도한때 좋은반응을보였던시절이있었다</td>\n",
       "      <td>라인의 경우 일본에서 첫 선을 보인 뒤 유럽에서도 한때 좋은 반응을 보였던 시절이 있었다</td>\n",
       "      <td>라인의 경우 일본에서 첫선을 보인 뒤 유럽에서도 한때 좋은 반응을 보였던 시절이 있었다</td>\n",
       "      <td>0</td>\n",
       "      <td>0.563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8103 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           err_sentence  \\\n",
       "5          하지만 국민 지지가 뒷받침되면 국정 운영에 자신감과 탄력이더해진다는점도 분명하다   \n",
       "11                         국민 혈세로시장을 틀어막아 달라는것은 어불성설이다.   \n",
       "12                             차제에문제 병사 관리 실태를 일제히 점검하라   \n",
       "13     당시에도 군 경계 태세에 구멍이 뚫렸다는 비판이들끓었는데 또 이사단에서 사고가 터졌다.   \n",
       "14                                   군 총기사고는 잊을만하면발생한다.   \n",
       "...                                                 ...   \n",
       "35964     그러나 딸은죽은 엄마와의추억이 떠올라이미 오래전부터 피아노 레슨을 받지않고있었다.   \n",
       "35970  저출산, 저소득층의 사고, 장병의 불확실한 미래는기업의지속가능성을위협하는사회적 문제다.   \n",
       "35981                                 경선에선 역대 최대여성후보 바람   \n",
       "35986                      최대 관심사는 네이버가 유럽에서 첫선을보일 서비스다   \n",
       "35987        라인의 경우 일본에서 첫선을보인 뒤 유럽에서도한때 좋은반응을보였던시절이있었다   \n",
       "\n",
       "                                            res_sentence  \\\n",
       "5           하지만 국민지지가 뒷받침되면 국정운영에 자신감과 탄력이 더해진다는 점도 분명하다   \n",
       "11                          국민혈세로 시장을 틀어막아 달라는 것은 어불성설이다   \n",
       "12                              차제에 문제병사 관리 실태를 일제히 점검하라   \n",
       "13      당시에도 군경계 태세에 구멍이 뚫렸다는 비판이 들끓었는데 또 이 사단에서 사고가 터졌다   \n",
       "14                                   군총기 사고는 잊을 만하면 발생한다   \n",
       "...                                                  ...   \n",
       "35964  그러나 딸은 죽은 엄마와의 추억이 떠올라 이미 오래 전부터 피아노 레슨을 받지 않고...   \n",
       "35970  저출산 저소득층의 사고 장병의 불확실한 미래는 기업의 지속가능성을 위협하는 사회적 문제다   \n",
       "35981                               경선에 선 역대 최대 여성 후보 바람   \n",
       "35986                     최대 관심사는 네이버가 유럽에서 첫 선을 보일 서비스다   \n",
       "35987  라인의 경우 일본에서 첫 선을 보인 뒤 유럽에서도 한때 좋은 반응을 보였던 시절이 있었다   \n",
       "\n",
       "                                            cor_sentence  check  ratio  \n",
       "5         하지만 국민 지지가 뒷받침되면 국정 운영에 자신감과 탄력이 더해진다는 점도 분명하다      0  0.518  \n",
       "11                         국민 혈세로 시장을 틀어막아 달라는 것은 어불성설이다      0  0.491  \n",
       "12                             차제에 문제 병사 관리 실태를 일제히 점검하라      0  0.540  \n",
       "13     당시에도 군 경계 태세에 구멍이 뚫렸다는 비판이 들끓었는데 또 이 사단에서 사고가 터졌다      0  0.518  \n",
       "14                                  군 총기 사고는 잊을 만하면 발생한다      0  0.487  \n",
       "...                                                  ...    ...    ...  \n",
       "35964  그러나 딸은 죽은 엄마와의 추억이 떠올라 이미 오래전부터 피아노 레슨을 받지 않고 있었다      0  0.689  \n",
       "35970  저출산 저소득층의 사고 장병의 불확실한 미래는 기업의 지속 가능성을 위협하는 사회적...      0  0.745  \n",
       "35981                                경선에선 역대 최대 여성 후보 바람      0  0.487  \n",
       "35986                      최대 관심사는 네이버가 유럽에서 첫선을 보일 서비스다      0  0.714  \n",
       "35987   라인의 경우 일본에서 첫선을 보인 뒤 유럽에서도 한때 좋은 반응을 보였던 시절이 있었다      0  0.563  \n",
       "\n",
       "[8103 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[result_df['check'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_excel('./hugging_result.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리 후 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "with open('/home/yjtech2/Desktop/yurim/LLM/DATA/띄어쓰기문장부호오류.json', 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "    \n",
    "data = []\n",
    "for item in json_data['data']:\n",
    "    if 'annotation' in item:\n",
    "        annotation = item['annotation']\n",
    "        \n",
    "        if 'err_sentence' in annotation and 'cor_sentence' in annotation:\n",
    "            data.append({\n",
    "                'err_sentence': annotation['err_sentence'],\n",
    "                'cor_sentence': annotation['cor_sentence']\n",
    "            })\n",
    "            \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def text_clean(text):\n",
    "    # pattern = '([ㄱ-ㅎㅏ-ㅣ]+)'  # 한글 자음, 모음 제거\n",
    "    # text = re.sub(pattern, '', text)\n",
    "    \n",
    "    pattern = '[^\\w\\s]'         # 특수기호제거\n",
    "    text = re.sub(pattern, '', text)\n",
    "\n",
    "    return text \n",
    "\n",
    "df['err_sentence'] = df['err_sentence'].apply(text_clean)\n",
    "df['cor_sentence'] = df['cor_sentence'].apply(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>err_sentence</th>\n",
       "      <th>cor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>일손과시간이부족해 검증을 다못했다는 군색한변명은안통한다</td>\n",
       "      <td>일손과 시간이 부족해 검증을 다 못했다는 군색한 변명은 안 통한다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>총리 후보가사퇴할때마다대통령에게 오는타격은 엄청나다</td>\n",
       "      <td>총리 후보가 사퇴할 때마다 대통령에게 오는 타격은 엄청나다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이정부 들어 처음으로 박 대통령에대한부정적평가가 긍정적평가를 넘어선 것이다</td>\n",
       "      <td>이 정부 들어 처음으로 박 대통령에 대한 부정적 평가가 긍정적 평가를 넘어선 것이다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>대통령이지지율에일희일비할필요는 없다</td>\n",
       "      <td>대통령이 지지율에 일희일비할 필요는 없다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>위대한 업적을 남긴지도자일수록 반대여론을 무릅쓴 경우가많다</td>\n",
       "      <td>위대한 업적을 남긴 지도자일수록 반대 여론을 무릅쓴 경우가 많다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35995</th>\n",
       "      <td>서울 벗어나면 놀이터가없는마을도</td>\n",
       "      <td>서울 벗어나면 놀이터가 없는 마을도</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35996</th>\n",
       "      <td>집 밖으로나가 뛰어놀고싶은 어린이들에게 놀이터는 너무 멀리있거나 즐겁게 놀 만한기구가없다</td>\n",
       "      <td>집 밖으로 나가 뛰어놀고 싶은 어린이들에게 놀이터는 너무 멀리 있거나 즐겁게 놀 만...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35997</th>\n",
       "      <td>재미가없으니 어린이들이모이지않고 같이 놀 친구가없어서 더욱 갈일이없어진다</td>\n",
       "      <td>재미가 없으니 어린이들이 모이지 않고 같이 놀 친구가 없어서 더욱 갈 일이 없어진다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35998</th>\n",
       "      <td>어린이들이 뛰어놀수있는 공간마저도 지역에따라 격차를 보이고있는것이다</td>\n",
       "      <td>어린이들이 뛰어놀 수 있는 공간마저도 지역에 따라 격차를 보이고 있는 것이다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35999</th>\n",
       "      <td>그러나 막상아이들을 키우는 주민들의생각은 다르다</td>\n",
       "      <td>그러나 막상 아이들을 키우는 주민들의 생각은 다르다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            err_sentence  \\\n",
       "0                         일손과시간이부족해 검증을 다못했다는 군색한변명은안통한다   \n",
       "1                           총리 후보가사퇴할때마다대통령에게 오는타격은 엄청나다   \n",
       "2              이정부 들어 처음으로 박 대통령에대한부정적평가가 긍정적평가를 넘어선 것이다   \n",
       "3                                    대통령이지지율에일희일비할필요는 없다   \n",
       "4                       위대한 업적을 남긴지도자일수록 반대여론을 무릅쓴 경우가많다   \n",
       "...                                                  ...   \n",
       "35995                                  서울 벗어나면 놀이터가없는마을도   \n",
       "35996  집 밖으로나가 뛰어놀고싶은 어린이들에게 놀이터는 너무 멀리있거나 즐겁게 놀 만한기구가없다   \n",
       "35997           재미가없으니 어린이들이모이지않고 같이 놀 친구가없어서 더욱 갈일이없어진다   \n",
       "35998              어린이들이 뛰어놀수있는 공간마저도 지역에따라 격차를 보이고있는것이다   \n",
       "35999                         그러나 막상아이들을 키우는 주민들의생각은 다르다   \n",
       "\n",
       "                                            cor_sentence  \n",
       "0                   일손과 시간이 부족해 검증을 다 못했다는 군색한 변명은 안 통한다  \n",
       "1                       총리 후보가 사퇴할 때마다 대통령에게 오는 타격은 엄청나다  \n",
       "2         이 정부 들어 처음으로 박 대통령에 대한 부정적 평가가 긍정적 평가를 넘어선 것이다  \n",
       "3                                 대통령이 지지율에 일희일비할 필요는 없다  \n",
       "4                    위대한 업적을 남긴 지도자일수록 반대 여론을 무릅쓴 경우가 많다  \n",
       "...                                                  ...  \n",
       "35995                                서울 벗어나면 놀이터가 없는 마을도  \n",
       "35996  집 밖으로 나가 뛰어놀고 싶은 어린이들에게 놀이터는 너무 멀리 있거나 즐겁게 놀 만...  \n",
       "35997     재미가 없으니 어린이들이 모이지 않고 같이 놀 친구가 없어서 더욱 갈 일이 없어진다  \n",
       "35998         어린이들이 뛰어놀 수 있는 공간마저도 지역에 따라 격차를 보이고 있는 것이다  \n",
       "35999                       그러나 막상 아이들을 키우는 주민들의 생각은 다르다  \n",
       "\n",
       "[36000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing spacing correction: 100%|██████████| 36000/36000 [01:49<00:00, 329.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비교 완료\n",
      "정확도:  0.765\n",
      "비율 평균:  0.9126824166666568\n",
      "처리 완료!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"fiveflow/roberta-base-spacing\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"fiveflow/roberta-base-spacing\")\n",
    "\n",
    "# GPU 사용 가능시 GPU 사용\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# 레이블 정의\n",
    "label = [\"UNK\", \"PAD\", \"O\", \"B\", \"I\", \"E\", \"S\"]\n",
    "\n",
    "def apply_spacing_correction(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    try:\n",
    "        # 최대 토큰 길이 설정\n",
    "        max_token_length = 512 - 2  # CLS와 SEP 토큰을 위한 자리\n",
    "        \n",
    "        # 공백 제거된 텍스트 준비\n",
    "        org_text = text.replace(\" \", \"\")\n",
    "        corrected_sentences = []\n",
    "        \n",
    "        # 512 토큰 단위로 나누기\n",
    "        for start_idx in range(0, len(org_text), max_token_length):\n",
    "            chunk = org_text[start_idx:start_idx + max_token_length]\n",
    "            token_list = [tokenizer.cls_token_id]\n",
    "            for char in chunk:\n",
    "                token_list.extend(tokenizer.encode(char)[1:-1])  # CLS, SEP 토큰 제외\n",
    "            token_list.append(tokenizer.sep_token_id)\n",
    "            \n",
    "            tkd = torch.tensor(token_list).unsqueeze(0).to(device)\n",
    "            \n",
    "            # 모델 예측\n",
    "            with torch.no_grad():\n",
    "                outputs = model(tkd)\n",
    "                pred_idx = torch.argmax(outputs.logits, dim=-1)\n",
    "            \n",
    "            # 예측 결과를 문자열로 변환\n",
    "            pred_sent = \"\"\n",
    "            for char_idx, spc_idx in enumerate(pred_idx.squeeze()[1:-1]):\n",
    "                if char_idx >= len(chunk):  # 인덱스 범위 체크\n",
    "                    break\n",
    "                \n",
    "                curr_label = label[spc_idx]\n",
    "                if curr_label in [\"E\", \"S\"]:  # E나 S 태그가 있으면 띄어쓰기 추가\n",
    "                    pred_sent += chunk[char_idx] + \" \"\n",
    "                else:\n",
    "                    pred_sent += chunk[char_idx]\n",
    "            \n",
    "            corrected_sentences.append(pred_sent.strip())\n",
    "        \n",
    "        # 모든 청크를 다시 합치기\n",
    "        final_text = \" \".join(corrected_sentences)\n",
    "        return final_text.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "        return text  # 에러 발생시 원본 텍스트 반환\n",
    "\n",
    "def process_dataframe(df, text_column):\n",
    "    # 진행바 표시\n",
    "    tqdm.pandas(desc=\"Processing spacing correction\")\n",
    "    \n",
    "    # 띄어쓰기 교정 적용\n",
    "    df[\"res_sentence\"] = df[text_column].progress_apply(apply_spacing_correction)\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":        \n",
    "    # 띄어쓰기 교정 처리\n",
    "    processed_df = process_dataframe(df, \"err_sentence\")\n",
    "    processed_df['res_sentence'] = processed_df['res_sentence'].apply(text_clean)\n",
    "    \n",
    "    result_df = add_comparison_columns(processed_df)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(\"비교 완료\")\n",
    "    print('정확도: ', (len(result_df[result_df['check'] == 1]) / len(result_df)))\n",
    "    print('비율 평균: ', sum(result_df['ratio']) / len(result_df))\n",
    "    print('처리 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yjtech2/Desktop/yurim/anaconda3/envs/venv-llm/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-14 16:19:45.347088: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-14 16:19:45.372500: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-14 16:19:45.712210: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-14 16:19:47.702946] ====== Data Load Start ======\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 116 entries, 0 to 115\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   제목      116 non-null    object\n",
      " 1   질문내용    116 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.9+ KB\n",
      "None\n",
      "[2024-11-14 16:19:47.707436] ====== Data Load Finished ======\n",
      "[2024-11-14 16:19:47.707436] ====== Data Preprocessing Start ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing spacing correction: 100%|██████████| 116/116 [00:00<00:00, 291.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-14 16:19:48.107337] ====== Data Preprocessing Finished ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 데이터 불러오기\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path, encoding = 'cp949')\n",
    "    \n",
    "    print(df.info())\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# 모델 정의\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"fiveflow/roberta-base-spacing\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"fiveflow/roberta-base-spacing\")\n",
    "\n",
    "# GPU 사용 가능시 GPU 사용\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# 레이블 정의\n",
    "label = [\"UNK\", \"PAD\", \"O\", \"B\", \"I\", \"E\", \"S\"]\n",
    "\n",
    "def apply_spacing_correction(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    try:\n",
    "        # 최대 토큰 길이 설정\n",
    "        max_token_length = 512 - 2  # CLS와 SEP 토큰을 위한 자리\n",
    "        \n",
    "        # 공백 제거된 텍스트 준비\n",
    "        org_text = text.replace(\" \", \"\")\n",
    "        corrected_sentences = []\n",
    "        \n",
    "        # 512 토큰 단위로 나누기\n",
    "        for start_idx in range(0, len(org_text), max_token_length):\n",
    "            chunk = org_text[start_idx:start_idx + max_token_length]\n",
    "            token_list = [tokenizer.cls_token_id]\n",
    "            for char in chunk:\n",
    "                token_list.extend(tokenizer.encode(char)[1:-1])  # CLS, SEP 토큰 제외\n",
    "            token_list.append(tokenizer.sep_token_id)\n",
    "            \n",
    "            tkd = torch.tensor(token_list).unsqueeze(0).to(device)\n",
    "            \n",
    "            # 모델 예측\n",
    "            with torch.no_grad():\n",
    "                outputs = model(tkd)\n",
    "                pred_idx = torch.argmax(outputs.logits, dim=-1)\n",
    "            \n",
    "            # 예측 결과를 문자열로 변환\n",
    "            pred_sent = \"\"\n",
    "            for char_idx, spc_idx in enumerate(pred_idx.squeeze()[1:-1]):\n",
    "                if char_idx >= len(chunk):  # 인덱스 범위 체크\n",
    "                    break\n",
    "                \n",
    "                curr_label = label[spc_idx]\n",
    "                if curr_label in [\"E\", \"S\"]:  # E나 S 태그가 있으면 띄어쓰기 추가\n",
    "                    pred_sent += chunk[char_idx] + \" \"\n",
    "                else:\n",
    "                    pred_sent += chunk[char_idx]\n",
    "            \n",
    "            corrected_sentences.append(pred_sent.strip())\n",
    "        \n",
    "        # 모든 청크를 다시 합치기\n",
    "        final_text = \" \".join(corrected_sentences)\n",
    "        return final_text.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "        return text  # 에러 발생시 원본 텍스트 반환\n",
    "\n",
    "def process_dataframe(df, text_column):\n",
    "    # 진행바 표시\n",
    "    tqdm.pandas(desc=\"Processing spacing correction\")\n",
    "    \n",
    "    # 띄어쓰기 교정 적용\n",
    "    df[\"res_sentence\"] = df[text_column].progress_apply(apply_spacing_correction)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# 수행\n",
    "if __name__ == \"__main__\":\n",
    "    _now_time = datetime.now().__str__()\n",
    "    print(f'[{_now_time}] ====== Data Load Start ======')\n",
    "    df = load_data('/home/yjtech2/Desktop/yurim/LLM/DATA/냄새_악취_포함.csv')\n",
    "    _now_time = datetime.now().__str__()\n",
    "    print(f'[{_now_time}] ====== Data Load Finished ======')\n",
    "    \n",
    "    print(f'[{_now_time}] ====== Data Preprocessing Start ======')\n",
    "    processed_df = process_dataframe(df, \"제목\")\n",
    "    _now_time = datetime.now().__str__()\n",
    "    print(f'[{_now_time}] ====== Data Preprocessing Finished ======')\n",
    "\n",
    "    # processed_df = processed_df[['err_sentence', 'res_sentence', 'cor_sentence']]\n",
    "    \n",
    "    def text_clean(text):\n",
    "        # pattern = '([ㄱ-ㅎㅏ-ㅣ]+)'  # 한글 자음, 모음 제거\n",
    "        # text = re.sub(pattern, '', text)\n",
    "        \n",
    "        pattern = '[^\\w\\s]'         # 특수기호제거\n",
    "        text = re.sub(pattern, '', text)\n",
    "\n",
    "        return text \n",
    "    \n",
    "    processed_df['res_sentence'] = processed_df['res_sentence'].apply(text_clean)\n",
    "    # processed_df['cor_sentence'] = processed_df['cor_sentence'].apply(text_clean)\n",
    "    processed_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제목</th>\n",
       "      <th>질문내용</th>\n",
       "      <th>res_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>악취 나는 뮬이 계속 흘러내려 물 을 오염시키고 있습니다.</td>\n",
       "      <td>순창군 순창읍 남계리ㅇㅇㅇ일원\\n악취 나는 물 이 계속 흘러 내려 물을 오염시키고 ...</td>\n",
       "      <td>악취 나는 뮬이 계속 흘러내려 물을 오염시키고 있습니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>마을 골 목 길에  퇴비를 두어 악취 발생이 심하니 이동   조치해 주세요.</td>\n",
       "      <td>전라북도 순창군 ㅇㅇ면 마을 꼴목길에  퇴비를 가져다 놓음\\n바람이불면 골목안쪽으로...</td>\n",
       "      <td>마을 골목길에 퇴비를 두어 악취 발생이 심하니 이동조치 해주세요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>노후된 모정 보수    요청ㅓ</td>\n",
       "      <td>전라북도순창군구림면금천리89-2\\n치천마을의치천옆에모정이있는데설치한지30년이넘어서나...</td>\n",
       "      <td>노후된 모정 보수 요청ㅓ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>인도에 패기물 컨테이너 적치로 통행 불편</td>\n",
       "      <td>순창군 순창읍 ㅇㅇ리 ㅇㅇㅇ\\n인도에 폐기물 컨테이너가 있어 통행 불편 및 악취로 ...</td>\n",
       "      <td>인도에 패기물 컨테이너 적치로 통행 불편</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>이웃집 에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다</td>\n",
       "      <td>첨부     한 사진과 같이 이웃집에서 보일러 기름으로 추정되는 액체가 다량으로 유...</td>\n",
       "      <td>이웃집에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>복합악취의 수인한도는?</td>\n",
       "      <td>복합악취의 수인한도는?</td>\n",
       "      <td>복합악취의 수인 한도는</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>악취배출량 단위 및 산정방법은?</td>\n",
       "      <td>악취배출량 단위 및 산정방법</td>\n",
       "      <td>악취 배출량 단위 및 산정 방법은</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>단독 또는 공동주택에서 애완견 등을 사육하여 소음 등을 유발하는 경우 환경분쟁조정대...</td>\n",
       "      <td>단독 또는 공동주택에서 애완견이나 고양이 등 동물사육으로 인하여 소음, 악취 등을 ...</td>\n",
       "      <td>단독 또는 공동주택에서 애완견 등을 사육하여 소음 등을 유발하는 경우 환경분쟁 조정...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>악취배출사업장 기술지원 및 공공환경시설 악취기술진단, 악취물질 측정·분석 관련 질의응답</td>\n",
       "      <td>Q1: ○ (악취배출사업장 기술지원) 악취저감기술 지원의 신청방법과 무상지원 범위는...</td>\n",
       "      <td>악취배출사업장 기술지원 및 공공환경시설 악취기술 진단 악취물질 측정분석 관련 질의 응답</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>표시문의('소취', '냄새제거')</td>\n",
       "      <td>1종 세척제에 '소취' 또는 '냄새제거' 표시가 가능한가요?</td>\n",
       "      <td>표시 문의소취 냄새 제거</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    제목  \\\n",
       "0                     악취 나는 뮬이 계속 흘러내려 물 을 오염시키고 있습니다.   \n",
       "1           마을 골 목 길에  퇴비를 두어 악취 발생이 심하니 이동   조치해 주세요.   \n",
       "2                                     노후된 모정 보수    요청ㅓ   \n",
       "3                               인도에 패기물 컨테이너 적치로 통행 불편   \n",
       "4       이웃집 에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다   \n",
       "..                                                 ...   \n",
       "111                                       복합악취의 수인한도는?   \n",
       "112                                  악취배출량 단위 및 산정방법은?   \n",
       "113  단독 또는 공동주택에서 애완견 등을 사육하여 소음 등을 유발하는 경우 환경분쟁조정대...   \n",
       "114   악취배출사업장 기술지원 및 공공환경시설 악취기술진단, 악취물질 측정·분석 관련 질의응답   \n",
       "115                                 표시문의('소취', '냄새제거')   \n",
       "\n",
       "                                                  질문내용  \\\n",
       "0    순창군 순창읍 남계리ㅇㅇㅇ일원\\n악취 나는 물 이 계속 흘러 내려 물을 오염시키고 ...   \n",
       "1    전라북도 순창군 ㅇㅇ면 마을 꼴목길에  퇴비를 가져다 놓음\\n바람이불면 골목안쪽으로...   \n",
       "2    전라북도순창군구림면금천리89-2\\n치천마을의치천옆에모정이있는데설치한지30년이넘어서나...   \n",
       "3    순창군 순창읍 ㅇㅇ리 ㅇㅇㅇ\\n인도에 폐기물 컨테이너가 있어 통행 불편 및 악취로 ...   \n",
       "4    첨부     한 사진과 같이 이웃집에서 보일러 기름으로 추정되는 액체가 다량으로 유...   \n",
       "..                                                 ...   \n",
       "111                                       복합악취의 수인한도는?   \n",
       "112                                    악취배출량 단위 및 산정방법   \n",
       "113  단독 또는 공동주택에서 애완견이나 고양이 등 동물사육으로 인하여 소음, 악취 등을 ...   \n",
       "114  Q1: ○ (악취배출사업장 기술지원) 악취저감기술 지원의 신청방법과 무상지원 범위는...   \n",
       "115                  1종 세척제에 '소취' 또는 '냄새제거' 표시가 가능한가요?   \n",
       "\n",
       "                                          res_sentence  \n",
       "0                       악취 나는 뮬이 계속 흘러내려 물을 오염시키고 있습니다  \n",
       "1                  마을 골목길에 퇴비를 두어 악취 발생이 심하니 이동조치 해주세요  \n",
       "2                                        노후된 모정 보수 요청ㅓ  \n",
       "3                               인도에 패기물 컨테이너 적치로 통행 불편  \n",
       "4        이웃집에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다  \n",
       "..                                                 ...  \n",
       "111                                       복합악취의 수인 한도는  \n",
       "112                                 악취 배출량 단위 및 산정 방법은  \n",
       "113  단독 또는 공동주택에서 애완견 등을 사육하여 소음 등을 유발하는 경우 환경분쟁 조정...  \n",
       "114   악취배출사업장 기술지원 및 공공환경시설 악취기술 진단 악취물질 측정분석 관련 질의 응답  \n",
       "115                                      표시 문의소취 냄새 제거  \n",
       "\n",
       "[116 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing spelling correction: 100%|██████████| 116/116 [00:07<00:00, 15.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, pipeline\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def apply_spelling_correction(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return \"\"\n",
    "    \n",
    "    try:\n",
    "        # 최대 토큰 길이 설정\n",
    "        max_token_length = 128 - 2  # CLS와 SEP 토큰을 위한 자리\n",
    "        \n",
    "        # 공백 제거된 텍스트 준비\n",
    "        org_text = text.replace(\" \", \"\")\n",
    "        corrected_sentences = []\n",
    "        \n",
    "        # 입력 텍스트가 비어있는 경우 처리\n",
    "        if not org_text:\n",
    "            return \"\"\n",
    "        \n",
    "        # 청크 단위로 처리\n",
    "        for start_idx in range(0, len(org_text), max_token_length):\n",
    "            chunk = org_text[start_idx:start_idx + max_token_length]\n",
    "            \n",
    "            # 각 청크에 대해 모델 처리\n",
    "            input_encoding = tokenizer(\"맞춤법을 고쳐주세요: \" + chunk, return_tensors=\"pt\")\n",
    "            input_ids = input_encoding.input_ids.to(device)\n",
    "            attention_mask = input_encoding.attention_mask.to(device)\n",
    "            \n",
    "            output_encoding = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=128,\n",
    "                num_beams=5,\n",
    "                early_stopping=True,\n",
    "            )\n",
    "            \n",
    "            chunk_result = tokenizer.decode(output_encoding[0], skip_special_tokens=True)\n",
    "            if chunk_result.strip():  # 빈 문자열이 아닌 경우에만 추가\n",
    "                corrected_sentences.append(chunk_result.strip())\n",
    "        \n",
    "        # 모든 청크를 다시 합치기\n",
    "        final_text = \" \".join(corrected_sentences)\n",
    "        return final_text.strip() or \"\"  # 빈 문자열이면 \"\" 반환\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "def process_dataframe(df, text_column):\n",
    "    tqdm.pandas(desc=\"Processing spelling correction\")\n",
    "    df[\"spacing_sentence\"] = df[text_column].progress_apply(apply_spelling_correction)\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# 모델 정의 (전역 변수로 유지)\n",
    "model = T5ForConditionalGeneration.from_pretrained('j5ng/et5-typos-corrector')\n",
    "tokenizer = T5Tokenizer.from_pretrained('j5ng/et5-typos-corrector')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    processed_df = process_dataframe(processed_df, \"res_sentence\")\n",
    "    print('처리 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제목</th>\n",
       "      <th>질문내용</th>\n",
       "      <th>res_sentence</th>\n",
       "      <th>spacing_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>악취 나는 뮬이 계속 흘러내려 물 을 오염시키고 있습니다.</td>\n",
       "      <td>순창군 순창읍 남계리ㅇㅇㅇ일원\\n악취 나는 물 이 계속 흘러 내려 물을 오염시키고 ...</td>\n",
       "      <td>악취 나는 뮬이 계속 흘러내려 물을 오염시키고 있습니다</td>\n",
       "      <td>냄새나는 뮬이 계속 흘러내려 물을 오염시키고 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>마을 골 목 길에  퇴비를 두어 악취 발생이 심하니 이동   조치해 주세요.</td>\n",
       "      <td>전라북도 순창군 ㅇㅇ면 마을 꼴목길에  퇴비를 가져다 놓음\\n바람이불면 골목안쪽으로...</td>\n",
       "      <td>마을 골목길에 퇴비를 두어 악취 발생이 심하니 이동조치 해주세요</td>\n",
       "      <td>마을 골목길에 퇴비를 두어 악취 발생이 심하니 이동 조치 해 주세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>노후된 모정 보수    요청ㅓ</td>\n",
       "      <td>전라북도순창군구림면금천리89-2\\n치천마을의치천옆에모정이있는데설치한지30년이넘어서나...</td>\n",
       "      <td>노후된 모정 보수 요청ㅓ</td>\n",
       "      <td>노후된 이모 정보 수 요청.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>인도에 패기물 컨테이너 적치로 통행 불편</td>\n",
       "      <td>순창군 순창읍 ㅇㅇ리 ㅇㅇㅇ\\n인도에 폐기물 컨테이너가 있어 통행 불편 및 악취로 ...</td>\n",
       "      <td>인도에 패기물 컨테이너 적치로 통행 불편</td>\n",
       "      <td>인도에 패기물 컨테이너 적치로통행 불편.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>이웃집 에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다</td>\n",
       "      <td>첨부     한 사진과 같이 이웃집에서 보일러 기름으로 추정되는 액체가 다량으로 유...</td>\n",
       "      <td>이웃집에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다</td>\n",
       "      <td>이웃집에서 보일러 기름으로 추측되는 물질이다량으로 유출되어 주변에 피해를 쥽니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>복합악취의 수인한도는?</td>\n",
       "      <td>복합악취의 수인한도는?</td>\n",
       "      <td>복합악취의 수인 한도는</td>\n",
       "      <td>복합 악취의 수인 한도는.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>악취배출량 단위 및 산정방법은?</td>\n",
       "      <td>악취배출량 단위 및 산정방법</td>\n",
       "      <td>악취 배출량 단위 및 산정 방법은</td>\n",
       "      <td>냄새 배출량 단위 및 산정 방법은.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>단독 또는 공동주택에서 애완견 등을 사육하여 소음 등을 유발하는 경우 환경분쟁조정대...</td>\n",
       "      <td>단독 또는 공동주택에서 애완견이나 고양이 등 동물사육으로 인하여 소음, 악취 등을 ...</td>\n",
       "      <td>단독 또는 공동주택에서 애완견 등을 사육하여 소음 등을 유발하는 경우 환경분쟁 조정...</td>\n",
       "      <td>단독 또는 공동주택에서 애완견을 사육하여 소음 등을 유발하는 경우 환경분쟁 조정 대...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>악취배출사업장 기술지원 및 공공환경시설 악취기술진단, 악취물질 측정·분석 관련 질의응답</td>\n",
       "      <td>Q1: ○ (악취배출사업장 기술지원) 악취저감기술 지원의 신청방법과 무상지원 범위는...</td>\n",
       "      <td>악취배출사업장 기술지원 및 공공환경시설 악취기술 진단 악취물질 측정분석 관련 질의 응답</td>\n",
       "      <td>냄새 배출 사업장 기술 지원 및 공공 환경 시설 악취 기술 진단 악취 물질 측정 분...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>표시문의('소취', '냄새제거')</td>\n",
       "      <td>1종 세척제에 '소취' 또는 '냄새제거' 표시가 가능한가요?</td>\n",
       "      <td>표시 문의소취 냄새 제거</td>\n",
       "      <td>표시 문의 소취 냄새 제거.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    제목  \\\n",
       "0                     악취 나는 뮬이 계속 흘러내려 물 을 오염시키고 있습니다.   \n",
       "1           마을 골 목 길에  퇴비를 두어 악취 발생이 심하니 이동   조치해 주세요.   \n",
       "2                                     노후된 모정 보수    요청ㅓ   \n",
       "3                               인도에 패기물 컨테이너 적치로 통행 불편   \n",
       "4       이웃집 에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다   \n",
       "..                                                 ...   \n",
       "111                                       복합악취의 수인한도는?   \n",
       "112                                  악취배출량 단위 및 산정방법은?   \n",
       "113  단독 또는 공동주택에서 애완견 등을 사육하여 소음 등을 유발하는 경우 환경분쟁조정대...   \n",
       "114   악취배출사업장 기술지원 및 공공환경시설 악취기술진단, 악취물질 측정·분석 관련 질의응답   \n",
       "115                                 표시문의('소취', '냄새제거')   \n",
       "\n",
       "                                                  질문내용  \\\n",
       "0    순창군 순창읍 남계리ㅇㅇㅇ일원\\n악취 나는 물 이 계속 흘러 내려 물을 오염시키고 ...   \n",
       "1    전라북도 순창군 ㅇㅇ면 마을 꼴목길에  퇴비를 가져다 놓음\\n바람이불면 골목안쪽으로...   \n",
       "2    전라북도순창군구림면금천리89-2\\n치천마을의치천옆에모정이있는데설치한지30년이넘어서나...   \n",
       "3    순창군 순창읍 ㅇㅇ리 ㅇㅇㅇ\\n인도에 폐기물 컨테이너가 있어 통행 불편 및 악취로 ...   \n",
       "4    첨부     한 사진과 같이 이웃집에서 보일러 기름으로 추정되는 액체가 다량으로 유...   \n",
       "..                                                 ...   \n",
       "111                                       복합악취의 수인한도는?   \n",
       "112                                    악취배출량 단위 및 산정방법   \n",
       "113  단독 또는 공동주택에서 애완견이나 고양이 등 동물사육으로 인하여 소음, 악취 등을 ...   \n",
       "114  Q1: ○ (악취배출사업장 기술지원) 악취저감기술 지원의 신청방법과 무상지원 범위는...   \n",
       "115                  1종 세척제에 '소취' 또는 '냄새제거' 표시가 가능한가요?   \n",
       "\n",
       "                                          res_sentence  \\\n",
       "0                       악취 나는 뮬이 계속 흘러내려 물을 오염시키고 있습니다   \n",
       "1                  마을 골목길에 퇴비를 두어 악취 발생이 심하니 이동조치 해주세요   \n",
       "2                                        노후된 모정 보수 요청ㅓ   \n",
       "3                               인도에 패기물 컨테이너 적치로 통행 불편   \n",
       "4        이웃집에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다   \n",
       "..                                                 ...   \n",
       "111                                       복합악취의 수인 한도는   \n",
       "112                                 악취 배출량 단위 및 산정 방법은   \n",
       "113  단독 또는 공동주택에서 애완견 등을 사육하여 소음 등을 유발하는 경우 환경분쟁 조정...   \n",
       "114   악취배출사업장 기술지원 및 공공환경시설 악취기술 진단 악취물질 측정분석 관련 질의 응답   \n",
       "115                                      표시 문의소취 냄새 제거   \n",
       "\n",
       "                                      spacing_sentence  \n",
       "0                       냄새나는 뮬이 계속 흘러내려 물을 오염시키고 있습니다.  \n",
       "1               마을 골목길에 퇴비를 두어 악취 발생이 심하니 이동 조치 해 주세요.  \n",
       "2                                      노후된 이모 정보 수 요청.  \n",
       "3                               인도에 패기물 컨테이너 적치로통행 불편.  \n",
       "4        이웃집에서 보일러 기름으로 추측되는 물질이다량으로 유출되어 주변에 피해를 쥽니다.  \n",
       "..                                                 ...  \n",
       "111                                     복합 악취의 수인 한도는.  \n",
       "112                                냄새 배출량 단위 및 산정 방법은.  \n",
       "113  단독 또는 공동주택에서 애완견을 사육하여 소음 등을 유발하는 경우 환경분쟁 조정 대...  \n",
       "114  냄새 배출 사업장 기술 지원 및 공공 환경 시설 악취 기술 진단 악취 물질 측정 분...  \n",
       "115                                    표시 문의 소취 냄새 제거.  \n",
       "\n",
       "[116 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
