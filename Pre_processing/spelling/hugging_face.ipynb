{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ET5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yjtech2/Desktop/yurim/anaconda3/envs/venv-llm/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-14 14:59:27.152165: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-14 14:59:27.178123: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-14 14:59:27.521660: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14400 entries, 0 to 14399\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   err_sentence  14400 non-null  object\n",
      " 1   cor_sentence  14400 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 225.1+ KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing spelling correction: 100%|██████████| 14400/14400 [19:24<00:00, 12.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리 완료!\n",
      "비교 완료\n",
      "정확도:  0.265625\n",
      "비율 평균:  0.7866309027777771\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, pipeline\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "        \n",
    "    data = []\n",
    "    for item in json_data['data']:\n",
    "        if 'annotation' in item:\n",
    "            annotation = item['annotation']\n",
    "            \n",
    "            if 'err_sentence' in annotation and 'cor_sentence' in annotation:\n",
    "                data.append({\n",
    "                    'err_sentence': annotation['err_sentence'],\n",
    "                    'cor_sentence': annotation['cor_sentence']\n",
    "                })\n",
    "                \n",
    "    df = pd.DataFrame(data)\n",
    "    print(df.info())\n",
    "    # None 값을 빈 문자열로 대체\n",
    "    df = df.fillna('')\n",
    "    return df\n",
    "\n",
    "def apply_spelling_correction(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return \"\"\n",
    "    \n",
    "    try:\n",
    "        # 최대 토큰 길이 설정\n",
    "        max_token_length = 128 - 2  # CLS와 SEP 토큰을 위한 자리\n",
    "        \n",
    "        # 공백 제거된 텍스트 준비\n",
    "        org_text = text.replace(\" \", \"\")\n",
    "        corrected_sentences = []\n",
    "        \n",
    "        # 입력 텍스트가 비어있는 경우 처리\n",
    "        if not org_text:\n",
    "            return \"\"\n",
    "        \n",
    "        # 청크 단위로 처리\n",
    "        for start_idx in range(0, len(org_text), max_token_length):\n",
    "            chunk = org_text[start_idx:start_idx + max_token_length]\n",
    "            \n",
    "            # 각 청크에 대해 모델 처리\n",
    "            input_encoding = tokenizer(\"맞춤법을 고쳐주세요: \" + chunk, return_tensors=\"pt\")\n",
    "            input_ids = input_encoding.input_ids.to(device)\n",
    "            attention_mask = input_encoding.attention_mask.to(device)\n",
    "            \n",
    "            output_encoding = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=128,\n",
    "                num_beams=5,\n",
    "                early_stopping=True,\n",
    "            )\n",
    "            \n",
    "            chunk_result = tokenizer.decode(output_encoding[0], skip_special_tokens=True)\n",
    "            if chunk_result.strip():  # 빈 문자열이 아닌 경우에만 추가\n",
    "                corrected_sentences.append(chunk_result.strip())\n",
    "        \n",
    "        # 모든 청크를 다시 합치기\n",
    "        final_text = \" \".join(corrected_sentences)\n",
    "        return final_text.strip() or \"\"  # 빈 문자열이면 \"\" 반환\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "def process_dataframe(df, text_column):\n",
    "    # None 값을 빈 문자열로 대체\n",
    "    df[text_column] = df[text_column].fillna('')\n",
    "    \n",
    "    tqdm.pandas(desc=\"Processing spelling correction\")\n",
    "    df[\"res_sentence\"] = df[text_column].progress_apply(apply_spelling_correction)\n",
    "    \n",
    "    # None 값을 빈 문자열로 대체\n",
    "    df[\"res_sentence\"] = df[\"res_sentence\"].fillna('')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calculate_spacing_similarity(row):\n",
    "    \"\"\"\n",
    "    두 문장 간의 유사도를 계산하는 함수 - 단어별 일치율 기반\n",
    "    \"\"\"\n",
    "    # 빈 문자열 처리\n",
    "    if not row['res_sentence'] or not row['cor_sentence']:\n",
    "        return 0.0\n",
    "\n",
    "    # 문장을 띄어쓰기로 분할하여 각 단어 비교\n",
    "    res_words = row['res_sentence'].split()\n",
    "    cor_words = row['cor_sentence'].split()\n",
    "\n",
    "    # 비교할 단어 쌍의 수\n",
    "    max_len = max(len(res_words), len(cor_words))\n",
    "    if max_len == 0:\n",
    "        return 1.0  # 둘 다 빈 문장일 경우 100% 일치로 처리\n",
    "\n",
    "    # 단어별 일치율 계산\n",
    "    match_count = sum(1 for res_word, cor_word in zip(res_words, cor_words) if res_word == cor_word)\n",
    "    word_accuracy = match_count / max_len\n",
    "\n",
    "    # 전체 문자열의 유사도 계산 (띄어쓰기 포함)\n",
    "    similarity = SequenceMatcher(None, row['res_sentence'], row['cor_sentence']).ratio()\n",
    "\n",
    "    # 최종 비율 (가중치는 조정 가능)\n",
    "    final_ratio = (similarity + word_accuracy) / 2\n",
    "\n",
    "    return round(final_ratio, 3)\n",
    "\n",
    "def add_comparison_columns(df):\n",
    "    # None 값을 빈 문자열로 대체\n",
    "    df['res_sentence'] = df['res_sentence'].fillna('')\n",
    "    df['cor_sentence'] = df['cor_sentence'].fillna('')\n",
    "    \n",
    "    # check 컬럼 추가 (완전히 같으면 1, 다르면 0)\n",
    "    df['check'] = (df['res_sentence'] == df['cor_sentence']).astype(int)\n",
    "    \n",
    "    # ratio 컬럼 추가\n",
    "    df['ratio'] = df.apply(calculate_spacing_similarity, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def text_clean(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "        \n",
    "    pattern = '[^\\w\\s]'         # 특수기호제거\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text \n",
    "\n",
    "# 모델 정의 (전역 변수로 유지)\n",
    "model = T5ForConditionalGeneration.from_pretrained('j5ng/et5-typos-corrector')\n",
    "tokenizer = T5Tokenizer.from_pretrained('j5ng/et5-typos-corrector')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = load_data('/home/yjtech2/Desktop/yurim/LLM/DATA/맞춤법오류_자유게시판.json')\n",
    "    processed_df = process_dataframe(df, \"err_sentence\")\n",
    "    print('처리 완료!')\n",
    "\n",
    "    processed_df = processed_df[['err_sentence', 'res_sentence', 'cor_sentence']]\n",
    "    \n",
    "    processed_df['res_sentence'] = processed_df['res_sentence'].apply(text_clean)\n",
    "    processed_df['cor_sentence'] = processed_df['cor_sentence'].apply(text_clean)\n",
    "    \n",
    "    result_df = add_comparison_columns(processed_df)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(\"비교 완료\")\n",
    "    print('정확도: ', (len(result_df[result_df['check'] == 1]) / len(result_df)))\n",
    "    print('비율 평균: ', sum(result_df['ratio']) / len(result_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>err_sentence</th>\n",
       "      <th>res_sentence</th>\n",
       "      <th>cor_sentence</th>\n",
       "      <th>check</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>오늘도 다너를 외우러 와따요</td>\n",
       "      <td>오늘도 너를 외우러 왔어요</td>\n",
       "      <td>오늘도 단어를 외우러 왔어요</td>\n",
       "      <td>0</td>\n",
       "      <td>0.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>오늘은 추석 연휴동안 놀고 먹으며 학회 레포트를 쓰는 영상 준비해보았습니디</td>\n",
       "      <td>오늘은 추석 연휴 동안 놀고 먹으며 학회리포트를 쓰는 영상 준비해 보았습니다</td>\n",
       "      <td>오늘은 추석 연휴 동안 놀고먹으며 학회 리포트를 쓰는 영상 준비해 보았습니다</td>\n",
       "      <td>0</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>요즘 새로 살까말까 고민중인데 대학원 가면 새로 살것 같기도 하구 그러네요</td>\n",
       "      <td>요즘 새로 살까 말까 고민 중인데 대학원 가면 새로 살 것 같기도 하고 그러네요</td>\n",
       "      <td>요즘 새로 살까 말까 고민 중인데 대학원 가면 새로 살 것 같기도 하고 그러네요</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>요즘 영어 문제르 안 풀어서 실력이 내려가고 있는거 가타요.</td>\n",
       "      <td>요즘 영어 문제를 안 풀어서 실력이 내려가고 있는 거 같아요</td>\n",
       "      <td>요즘 영어 문제를 안 풀어서 실력이 내려가고 있는 거 같아요</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>원래 좋아하는 건 잘 찾아 외우는 능력이 잇서서 말이죠</td>\n",
       "      <td>원래 좋아하는 건 잘 찾아 외우는 능력이 있어서 말이죠</td>\n",
       "      <td>원래 좋아하는 것은 잘 찾아 외우는 능력이 있어서 말이죠</td>\n",
       "      <td>0</td>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14395</th>\n",
       "      <td>그 사람 이야기하는거 아님</td>\n",
       "      <td>그 사람 이야기하는 거 아님</td>\n",
       "      <td>그 사람 이야기하는 거 아님</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14396</th>\n",
       "      <td>그러다가 저 연세대갈사람 이 생사람 잡으면서 동일인물이라고 해서 기세등등해짐</td>\n",
       "      <td>그러다가 저 연세대 갈 사람이 생사람 잡으면서 동일 인물이라고 해서 기세 등등해짐</td>\n",
       "      <td>그러다가 저 연세대 갈 사람이 생사람 잡으면서 동일 인물이라고 해서 기세등등해짐</td>\n",
       "      <td>0</td>\n",
       "      <td>0.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14397</th>\n",
       "      <td>그런것들은 수능 공부를 병행하면서 준비해주시면 됩니다.</td>\n",
       "      <td>그런 것들은 수능 공부를 병행하면서 준비해 주시면 됩니다</td>\n",
       "      <td>그런 것들은 수능 공부를 병행하면서 준비해 주시면 됩니다</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14398</th>\n",
       "      <td>그리고 오늘은 유독 많은 일이 있었던거 같네요</td>\n",
       "      <td>그리고 오늘은 유독 많은 일이 있었던 거 같네요</td>\n",
       "      <td>그리고 오늘은 유독 많은 일이 있었던 거 같네요</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14399</th>\n",
       "      <td>그림까지 포함해서 한장 분량을 나올 정도로 하는게 적당한 것 같아요!</td>\n",
       "      <td>그림까지 포함해서 한 장 분량을 나올 정도로 하는 게 적당한 것 같아요</td>\n",
       "      <td>그림까지 포함해서 한 장 분량을 나올 정도로 하는 게 적당한 것 같아요</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     err_sentence  \\\n",
       "0                                 오늘도 다너를 외우러 와따요   \n",
       "1       오늘은 추석 연휴동안 놀고 먹으며 학회 레포트를 쓰는 영상 준비해보았습니디   \n",
       "2       요즘 새로 살까말까 고민중인데 대학원 가면 새로 살것 같기도 하구 그러네요   \n",
       "3               요즘 영어 문제르 안 풀어서 실력이 내려가고 있는거 가타요.   \n",
       "4                  원래 좋아하는 건 잘 찾아 외우는 능력이 잇서서 말이죠   \n",
       "...                                           ...   \n",
       "14395                              그 사람 이야기하는거 아님   \n",
       "14396  그러다가 저 연세대갈사람 이 생사람 잡으면서 동일인물이라고 해서 기세등등해짐   \n",
       "14397              그런것들은 수능 공부를 병행하면서 준비해주시면 됩니다.   \n",
       "14398                   그리고 오늘은 유독 많은 일이 있었던거 같네요   \n",
       "14399      그림까지 포함해서 한장 분량을 나올 정도로 하는게 적당한 것 같아요!   \n",
       "\n",
       "                                        res_sentence  \\\n",
       "0                                     오늘도 너를 외우러 왔어요   \n",
       "1         오늘은 추석 연휴 동안 놀고 먹으며 학회리포트를 쓰는 영상 준비해 보았습니다   \n",
       "2       요즘 새로 살까 말까 고민 중인데 대학원 가면 새로 살 것 같기도 하고 그러네요   \n",
       "3                  요즘 영어 문제를 안 풀어서 실력이 내려가고 있는 거 같아요   \n",
       "4                     원래 좋아하는 건 잘 찾아 외우는 능력이 있어서 말이죠   \n",
       "...                                              ...   \n",
       "14395                                그 사람 이야기하는 거 아님   \n",
       "14396  그러다가 저 연세대 갈 사람이 생사람 잡으면서 동일 인물이라고 해서 기세 등등해짐   \n",
       "14397                그런 것들은 수능 공부를 병행하면서 준비해 주시면 됩니다   \n",
       "14398                     그리고 오늘은 유독 많은 일이 있었던 거 같네요   \n",
       "14399        그림까지 포함해서 한 장 분량을 나올 정도로 하는 게 적당한 것 같아요   \n",
       "\n",
       "                                       cor_sentence  check  ratio  \n",
       "0                                   오늘도 단어를 외우러 왔어요      0  0.823  \n",
       "1        오늘은 추석 연휴 동안 놀고먹으며 학회 리포트를 쓰는 영상 준비해 보았습니다      0  0.852  \n",
       "2      요즘 새로 살까 말까 고민 중인데 대학원 가면 새로 살 것 같기도 하고 그러네요      1  1.000  \n",
       "3                 요즘 영어 문제를 안 풀어서 실력이 내려가고 있는 거 같아요      1  1.000  \n",
       "4                   원래 좋아하는 것은 잘 찾아 외우는 능력이 있어서 말이죠      0  0.920  \n",
       "...                                             ...    ...    ...  \n",
       "14395                               그 사람 이야기하는 거 아님      1  1.000  \n",
       "14396  그러다가 저 연세대 갈 사람이 생사람 잡으면서 동일 인물이라고 해서 기세등등해짐      0  0.911  \n",
       "14397               그런 것들은 수능 공부를 병행하면서 준비해 주시면 됩니다      1  1.000  \n",
       "14398                    그리고 오늘은 유독 많은 일이 있었던 거 같네요      1  1.000  \n",
       "14399       그림까지 포함해서 한 장 분량을 나올 정도로 하는 게 적당한 것 같아요      1  1.000  \n",
       "\n",
       "[14400 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
